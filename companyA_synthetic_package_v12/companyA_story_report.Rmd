---
title: "Company A — Lean Production & Operations Story (Root Cause → Solution → Impact)"
author: "Operations Analytics (handcrafted narrative on synthetic raw data)"
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
output:
  html_document:
    toc: true
    toc_depth: 3
    theme: flatly
    df_print: paged
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, message = FALSE, warning = FALSE
)

suppressPackageStartupMessages({
  library(tidyverse)
  library(lubridate)
  library(scales)
})

ensure_pkg <- function(p){
  if (!requireNamespace(p, quietly = TRUE)) install.packages(p, repos = "https://cloud.r-project.org")
}
ensure_pkg("highcharter")
ensure_pkg("lpSolve")

library(highcharter)
library(lpSolve)

options(highcharter.theme = hc_theme_flat())
hc_lang <- list(thousandsSep = ",", decimalPoint = ".")

# Highcharter version compatibility: some versions do not have hc_lang()
hc_lang_safe <- function(h, lang_list){
  # If hc_lang exists, use it; otherwise try hc_opts(lang=...); else no-op.
  if (exists("hc_lang", where=asNamespace("highcharter"), inherits=FALSE)) {
    return(highcharter::hc_lang(h, lang_list))
  }
  if (exists("hc_opts", where=asNamespace("highcharter"), inherits=FALSE)) {
    return(highcharter::hc_opts(h, lang = lang_list))
  }
  h
}


# ---- run-from-anywhere path helper ----
get_script_dir <- function(){
  cmdArgs <- commandArgs(trailingOnly = FALSE)
  fileArgName <- "--file="
  m <- grep(fileArgName, cmdArgs)
  if (length(m) > 0) return(dirname(normalizePath(sub(fileArgName, "", cmdArgs[m]), winslash="/")))
  if (!is.null(sys.frames()[[1]]$ofile)) return(dirname(normalizePath(sys.frames()[[1]]$ofile, winslash="/")))
  if (requireNamespace("rstudioapi", quietly = TRUE) && rstudioapi::isAvailable()) {
    p <- rstudioapi::getActiveDocumentContext()$path
    if (nzchar(p)) return(dirname(normalizePath(p, winslash="/")))
  }
  normalizePath(getwd(), winslash="/")
}
PROJECT_ROOT <- get_script_dir()
base_dir <- file.path(PROJECT_ROOT, "companyA_synthetic")
dir.create(file.path(base_dir, "analysis_outputs_r"), showWarnings = FALSE, recursive = TRUE)
dir.create(file.path(base_dir, "optimization_outputs_r"), showWarnings = FALSE, recursive = TRUE)

COL_BEFORE <- "#2C3E50"
COL_AFTER  <- "#18BC9C"
COL_WARN   <- "#F39C12"
COL_BAD    <- "#E74C3C"

# Helper: highcharter time series
hc_timeseries <- function(df, x, y, group=NULL, title="", ytitle="", subtitle=""){
  df <- df %>% arrange({{x}})
  h <- highchart() %>%
    hc_chart(zoomType="x") %>%
    hc_title(text = title) %>%
    hc_subtitle(text = subtitle) %>%
    hc_xAxis(type="datetime") %>%
    hc_yAxis(title = list(text=ytitle)) %>%
    hc_tooltip(shared=TRUE, crosshairs=TRUE) %>% hc_lang_safe(hc_lang)
  if (is.null(group)){
    h <- h %>% hc_add_series(df, "line", hcaes(x={{x}}, y={{y}}))
  } else {
    h <- h %>% hc_add_series_list(
      df %>%
        group_by({{group}}) %>%
        group_map(~ list(
          name = unique(.x %>% pull({{group}})),
          type = "line",
          data = .x %>% transmute(x=datetime_to_timestamp({{x}}), y={{y}}) %>% list_parse2()
        ))
    )
  }
  h
}

datetime_to_timestamp <- function(x){
  as.numeric(as.POSIXct(x)) * 1000
}

```

# 1) What this report does (and why it looks like a human analysis)

Instead of jumping straight to a **Before vs After dashboard**, this report follows a typical ops workflow:

1. **Baseline deep dive (BEFORE only)**  
   Break production performance down into *where time goes*, *where queues form*, and *where defects appear*.

2. **Problem statement (Lean wastes with evidence)**  
   Translate patterns into Lean waste types: waiting, defects, inventory, transportation.

3. **Solutions**  
   - Lean countermeasures (SMED, line balancing, quality-at-source, pull/kanban, leveling)
   - Optimization models (LP production + network flow) as the *decision engine*

4. **Impact**  
   Compare BEFORE vs AFTER only after the story is clear.

All metrics are computed from **raw event/transaction data** (no KPIs stored in the dataset).

# 2) Load raw data (before/after)

```{r load-raw}
load_scn <- function(scn){
  d <- file.path(base_dir, scn)
  list(
    prod = read_csv(file.path(d,"production_events.csv"), show_col_types = FALSE) %>%
      mutate(step_start_time = ymd_hms(step_start_time),
             step_end_time   = ymd_hms(step_end_time)),
    qi   = read_csv(file.path(d,"quality_inspections.csv"), show_col_types = FALSE) %>%
      mutate(inspection_time = ymd_hms(inspection_time)),
    inv  = read_csv(file.path(d,"inventory_snapshots.csv"), show_col_types = FALSE) %>%
      mutate(snapshot_date = ymd(snapshot_date)),
    dem  = read_csv(file.path(d,"demand_orders.csv"), show_col_types = FALSE) %>%
      mutate(order_date = ymd(order_date),
             due_date   = ymd(due_date)),
    sh   = read_csv(file.path(d,"shipments.csv"), show_col_types = FALSE) %>%
      mutate(ship_date = ymd(ship_date),
             planned_delivery_date = ymd(planned_delivery_date),
             actual_delivery_date  = ymd(actual_delivery_date)),
    lines = read_csv(file.path(d,"production_lines.csv"), show_col_types = FALSE),
    skus  = read_csv(file.path(d,"skus.csv"), show_col_types = FALSE),
    lanes = read_csv(file.path(d,"transportation_lanes.csv"), show_col_types = FALSE),
    customers = read_csv(file.path(d,"customers.csv"), show_col_types = FALSE),
    scenario = scn
  )
}

B <- load_scn("before")
A <- load_scn("after")
```

# 3) Baseline deep dive (BEFORE): What is breaking operations?

## 3.1 Demand shape (seasonality + spikes)

```{r demand-shape}
dem_wk <- B$dem %>%
  mutate(week = floor_date(due_date, "week", week_start=1),
         week_ts = datetime_to_timestamp(as.POSIXct(week))) %>%
  group_by(week, week_ts) %>%
  summarise(demand_qty = sum(demand_qty), orders=n(), .groups="drop") %>%
  arrange(week)

dem_wk %>%
  hchart(type = "line", hcaes(x = week_ts, y = demand_qty), name="Demand") %>%
  hc_chart(zoomType="x") %>%
  hc_title(text="Demand per week (BEFORE) — seasonality & spikes") %>%
  hc_xAxis(type="datetime") %>%
  hc_yAxis(title=list(text="Units")) %>%
  hc_tooltip(shared=TRUE, crosshairs=TRUE) %>%
  hc_colors(c(COL_BEFORE)) %>%
  hc_exporting(enabled = TRUE) %>%
  hc_lang_safe(hc_lang)

```

**How to read:** Demand spikes are not inherently bad — the question is whether production can *level-load* or whether spikes become **waiting, overtime, expediting**.

## 3.2 Throughput vs Demand gap (service risk)

```{r throughput-vs-demand}
# Make sure both demand and production are on the SAME week type (Date) before joining.
prod_wk <- B$prod %>%
  mutate(week = as.Date(floor_date(step_start_time, "week", week_start=1))) %>%
  group_by(week) %>%
  summarise(produced_qty=sum(produced_qty), .groups="drop")

dem_wk2 <- B$dem %>%
  mutate(week = as.Date(floor_date(due_date, "week", week_start=1))) %>%
  group_by(week) %>%
  summarise(demand_qty = sum(demand_qty), .groups="drop")

td <- full_join(dem_wk2, prod_wk, by="week") %>%
  replace_na(list(demand_qty=0, produced_qty=0)) %>%
  mutate(gap = produced_qty - demand_qty,
         week_ts = datetime_to_timestamp(as.POSIXct(week))) %>%
  arrange(week)

# Group13-style dynamic coloring (green/yellow/red) on the GAP column
colors_vector <- td %>%
  mutate(color = case_when(
    gap < 0 ~ COL_BAD,                                        # shortage risk
    gap < quantile(gap, 0.6, na.rm=TRUE) ~ COL_WARN,          # mild overproduction
    TRUE ~ COL_AFTER                                          # heavy overproduction
  )) %>% pull(color)

td %>%
  hchart(type="column", hcaes(x=week_ts, y=gap),
         name="Gap (Prod - Demand)",
         colorByPoint=TRUE,
         yAxis=1) %>%
  hc_colors(colors_vector) %>%
  hc_chart(zoomType="x") %>%
  hc_title(text="Throughput vs Demand (BEFORE)") %>%
  hc_subtitle(text="Column = gap; lines = produced & demand (zoomable)") %>%
  hc_xAxis(type="datetime") %>%
  hc_yAxis_multiples(
    list(title=list(text="Units")),
    list(title=list(text="Gap"), opposite=TRUE)
  ) %>%
  hc_add_series(td, type="line", hcaes(x=week_ts, y=produced_qty),
                name="Produced", color=COL_BEFORE, yAxis=0) %>%
  hc_add_series(td, type="line", hcaes(x=week_ts, y=demand_qty),
                name="Demand", color="#4285F4", dashStyle="ShortDot", yAxis=0) %>%
  hc_tooltip(shared=TRUE, crosshairs=TRUE) %>%
  hc_exporting(enabled = TRUE) %>%
  hc_lang_safe(hc_lang)

```

## 3.3 Value Stream Breakdown (where time goes): Cycle vs Waiting by step

We compute:
- **Cycle time** = `step_end_time - step_start_time`
- **Waiting time** = gap between current `step_start_time` and previous step's `step_end_time` in the same `work_order_id`

```{r vsm-breakdown}
p <- B$prod %>%
  mutate(cycle_min = as.numeric(difftime(step_end_time, step_start_time, units="mins"))) %>%
  arrange(work_order_id, step_start_time) %>%
  group_by(work_order_id) %>%
  mutate(prev_end = lag(step_end_time),
         wait_min = pmax(0, as.numeric(difftime(step_start_time, prev_end, units="mins")))) %>%
  ungroup()

by_step <- p %>%
  group_by(operation_step) %>%
  summarise(
    avg_cycle = mean(cycle_min, na.rm=TRUE),
    p95_cycle = quantile(cycle_min, 0.95, na.rm=TRUE),
    avg_wait  = mean(wait_min, na.rm=TRUE),
    p95_wait  = quantile(wait_min, 0.95, na.rm=TRUE),
    events = n(),
    .groups="drop"
  ) %>%
  arrange(desc(p95_wait))

# Stacked bars (avg cycle + avg wait)
stack_df <- by_step %>%
  select(operation_step, avg_cycle, avg_wait) %>%
  pivot_longer(cols=c(avg_cycle, avg_wait), names_to="component", values_to="minutes") %>%
  mutate(component = recode(component, avg_cycle="Avg cycle", avg_wait="Avg waiting"))

highchart() %>%
  hc_chart(type="bar") %>%
  hc_title(text="Value Stream time by operation step (BEFORE)") %>%
  hc_subtitle(text="Stacked: Avg cycle vs Avg waiting — waiting is pure waste") %>%
  hc_xAxis(categories = stack_df %>% distinct(operation_step) %>% pull(operation_step)) %>%
  hc_yAxis(title=list(text="Minutes")) %>%
  hc_plotOptions(series=list(stacking="normal")) %>%
  hc_add_series(
    stack_df %>% filter(component=="Avg cycle") %>% arrange(operation_step) %>% pull(minutes),
    name="Avg cycle", color=COL_BEFORE
  ) %>%
  hc_add_series(
    stack_df %>% filter(component=="Avg waiting") %>% arrange(operation_step) %>% pull(minutes),
    name="Avg waiting", color=COL_BAD
  ) %>%
  hc_tooltip(shared=TRUE) %>% hc_lang_safe(hc_lang)
```

**Interpretation guide:**  
- Steps with **high waiting** are your *queue points* (bottleneck symptom).  
- Steps with **high p95 cycle** indicate instability (variation) and/or rework loops.

## 3.4 Bottleneck confirmation: utilization heatmap (BEFORE)

```{r util-heatmap}
shift_hours <- c("2x8h"=16, "3x8h"=24, "1x10h"=10)
lines_cap <- B$lines %>%
  mutate(
    daily_capacity_machine_hours = if_else(is.na(daily_capacity_machine_hours),
                                           as.numeric(shift_hours[shift_pattern])*0.85,
                                           daily_capacity_machine_hours),
    weekly_capacity_machine_hours = daily_capacity_machine_hours * 6
  ) %>% select(production_line_id, weekly_capacity_machine_hours)

util <- B$prod %>%
  mutate(week = format(floor_date(step_start_time, "week", week_start=1), "%Y-%m-%d")) %>%
  group_by(week, production_line_id) %>%
  summarise(machine_hours=sum(machine_hours, na.rm=TRUE), .groups="drop") %>%
  left_join(lines_cap, by="production_line_id") %>%
  mutate(util = machine_hours / weekly_capacity_machine_hours)

# Heatmap data prep for highcharter (x=week index, y=line index)
weeks <- util %>% distinct(week) %>% arrange(week) %>% pull(week)
lines <- util %>% distinct(production_line_id) %>% arrange(production_line_id) %>% pull(production_line_id)

hm <- util %>%
  mutate(x = match(week, weeks) - 1,
         y = match(production_line_id, lines) - 1) %>%
  transmute(x, y, value = round(util, 2))

highchart() %>%
  hc_chart(type="heatmap", zoomType="xy") %>%
  hc_title(text="Bottleneck heatmap (BEFORE) — line utilization (machine)") %>%
  hc_xAxis(categories = weeks, title=list(text="Week")) %>%
  hc_yAxis(categories = lines, title=list(text="Line"), reversed=TRUE) %>%
  hc_colorAxis(stops = color_stops(n=5, colors = c("#ecf0f1", "#95a5a6", "#7f8c8d", "#34495e", "#000000"))) %>%
  hc_add_series(
    data = hm %>% list_parse(),
    name = "Utilization",
    borderWidth = 0.5
  ) %>%
  hc_tooltip(formatter = JS("function(){return '<b>Week:</b> '+ this.series.xAxis.categories[this.point.x] + 
                                     '<br><b>Line:</b> '+ this.series.yAxis.categories[this.point.y] +
                                     '<br><b>Util:</b> '+ this.point.value;}")) %>% hc_lang_safe(hc_lang)
```

**What to look for:** persistent dark bands = chronic bottleneck; random spikes = instability (breakdowns / changeover / staffing).

## 3.5 Quality breakdown: Pareto of defect types (BEFORE)

```{r defect-pareto}
qi <- B$qi %>% mutate(defect_code = replace_na(defect_code, "NONE"))
def <- qi %>%
  filter(defect_code != "NONE") %>%
  group_by(defect_code) %>%
  summarise(defects = sum(defects_found_qty, na.rm=TRUE), .groups="drop") %>%
  arrange(desc(defects)) %>%
  mutate(pct = defects / sum(defects),
         cum = cumsum(pct))

top_n <- min(10, nrow(def))
def_top <- def %>% slice_head(n=top_n)

highchart() %>%
  hc_title(text="Defect Pareto (BEFORE) — top defect types") %>%
  hc_xAxis(categories = def_top$defect_code) %>%
  hc_yAxis_multiples(
    list(title=list(text="Defect qty")),
    list(title=list(text="Cumulative %"), opposite=TRUE, labels=list(format="{value}%"))
  ) %>%
  hc_add_series(name="Defects", type="column", data=def_top$defects, color=COL_BAD) %>%
  hc_add_series(name="Cum%", type="spline", data=round(def_top$cum*100,1), yAxis=1, color=COL_BEFORE) %>%
  hc_tooltip(shared=TRUE) %>% hc_lang_safe(hc_lang)
```

**Lean callout:** Pareto tells you where to focus **quality-at-source** first.

## 3.6 Delivery performance: lateness distribution (BEFORE)

```{r lateness}
sh <- B$sh %>%
  mutate(late_days = pmax(0, as.numeric(difftime(actual_delivery_date, planned_delivery_date, units="days"))))

# show distribution as interactive histogram
bins <- sh %>%
  mutate(bin = pmin(late_days, 15)) %>% # cap long tail
  count(bin)

highchart() %>%
  hc_title(text="Shipment lateness distribution (BEFORE)") %>%
  hc_subtitle(text="0 = on time; right tail = expediting / firefighting") %>%
  hc_xAxis(categories = as.character(bins$bin), title=list(text="Late days (capped at 15)")) %>%
  hc_yAxis(title=list(text="Shipments")) %>%
  hc_add_series(name="Shipments", type="column", data=bins$n, color=COL_BEFORE) %>% hc_lang_safe(hc_lang)
```

# 4) Problem statement: Lean wastes with evidence (BEFORE)

Based on the baseline charts:

- **Waiting (Queues):** Value Stream breakdown shows steps where *avg waiting dominates*.
- **Bottleneck:** Utilization heatmap shows lines with sustained high utilization.
- **Defects/Rework:** Pareto highlights defect types driving most quality loss.
- **Delivery delays:** Lateness histogram shows firefighting risk.
- **Inventory imbalance:** (implicit via demand/throughput gap and later backorders)

In Lean terms, this is a classic combo: **unlevel demand + bottleneck capacity + quality issues → waiting, expediting, and hidden WIP.**

# 5) Solutions: Lean countermeasures + Optimization engines

## 5.1 Lean countermeasures (what we changed in AFTER)

- **SMED / changeover reduction:** lower setup time volatility on the bottleneck line.
- **Line balancing:** shift some SKU mix away from the bottleneck; stabilize cycle times.
- **Quality at source:** reduce defect rate + rework loops (target top Pareto defects).
- **Pull signals:** reduce excess inventory / backorders by better syncing production with demand.
- **Logistics discipline:** reduce late shipments by planning lanes with capacity.

These are exactly the “after scenario” transformations encoded in the synthetic generator.

## 5.2 Optimization 1 — Production Planning LP (weekly)

The LP decides **how much each SKU to make on each line each week**, under machine-hour capacity.

```{r production-lp}
prod <- B$prod; lines_m <- B$lines; skus <- B$skus; dem <- B$dem; inv_snap <- B$inv

dem <- dem %>% mutate(week = format(floor_date(due_date, unit="week", week_start=1), "%Y-%m-%d"))
weeks <- sort(unique(dem$week))
sku_list <- sort(unique(skus$sku_id))

demand_wk <- dem %>% group_by(week, sku_id) %>%
  summarise(demand_qty=sum(demand_qty), avg_penalty=mean(penalty_cost_late), .groups="drop")

grid <- expand_grid(week=weeks, sku_id=sku_list) %>%
  left_join(demand_wk, by=c("week","sku_id")) %>%
  mutate(demand_qty = replace_na(demand_qty, 0),
         avg_penalty = replace_na(avg_penalty, median(dem$penalty_cost_late)))

unit_mh <- prod %>% filter(produced_qty > 0) %>%
  group_by(sku_id) %>%
  summarise(mh_per_unit = sum(machine_hours, na.rm=TRUE)/sum(produced_qty, na.rm=TRUE), .groups="drop") %>%
  right_join(skus %>% select(sku_id, product_category), by="sku_id") %>%
  group_by(product_category) %>%
  mutate(mh_per_unit = if_else(is.na(mh_per_unit), median(mh_per_unit, na.rm=TRUE), mh_per_unit)) %>%
  ungroup() %>%
  mutate(mh_per_unit = pmax(0.01, mh_per_unit)) %>%
  select(sku_id, mh_per_unit)

shift_hours <- c("2x8h"=16, "3x8h"=24, "1x10h"=10)
lines_cap <- lines_m %>%
  mutate(daily_capacity_machine_hours = if_else(is.na(daily_capacity_machine_hours),
                                               as.numeric(shift_hours[shift_pattern])*0.85,
                                               daily_capacity_machine_hours),
         weekly_capacity_machine_hours = daily_capacity_machine_hours * 6) %>%
  select(factory_id, production_line_id, weekly_capacity_machine_hours)

line_list <- sort(unique(lines_cap$production_line_id))
cap_map <- lines_cap %>% select(production_line_id, weekly_capacity_machine_hours) %>% deframe()

# eligibility: sku -> factory -> lines
sku_factory_hist <- prod %>% count(sku_id, factory_id, sort=TRUE) %>%
  group_by(sku_id) %>% slice_max(n, n=1, with_ties=FALSE) %>% ungroup() %>%
  select(sku_id, factory_id)
fallback <- skus %>% mutate(factory_id = if_else(product_category %in% c("Tee","Polo","Short","Dress"), "F1", "F2")) %>%
  select(sku_id, factory_id)
sku_factory <- fallback %>% left_join(sku_factory_hist, by="sku_id", suffix=c("_fb","_hist")) %>%
  mutate(factory_id = coalesce(factory_id_hist, factory_id_fb)) %>%
  select(sku_id, factory_id)

eligible <- sku_factory %>%
  left_join(lines_cap %>% select(factory_id, production_line_id), by="factory_id", relationship="many-to-many") %>%
  distinct(sku_id, production_line_id)
elig_set <- eligible %>% mutate(key=paste0(sku_id,"|",production_line_id)) %>% pull(key) %>% unique()

# costs
costs <- inv_snap %>%
  group_by(sku_id) %>%
  summarise(hold_cost_day = mean(holding_cost_per_unit_per_day, na.rm=TRUE),
            stockout_cost = mean(stockout_cost_per_unit, na.rm=TRUE), .groups="drop")
global_hold <- mean(costs$hold_cost_day, na.rm=TRUE)
global_stock <- mean(costs$stockout_cost, na.rm=TRUE)

costs <- tibble(sku_id=sku_list) %>% left_join(costs, by="sku_id") %>%
  mutate(hold_cost_day=replace_na(hold_cost_day, global_hold),
         stockout_cost=replace_na(stockout_cost, global_stock),
         hold_cost_week=hold_cost_day*7) %>%
  select(sku_id, hold_cost_week, stockout_cost)

# initial inventory (WH)
inv0 <- inv_snap %>% filter(location_id %in% c("WH_NORTH","WH_SOUTH")) %>% arrange(snapshot_date)
first_date <- if (nrow(inv0)>0) min(inv0$snapshot_date) else NA
inv0_by_sku <- inv_snap %>%
  filter(location_id %in% c("WH_NORTH","WH_SOUTH"), snapshot_date==first_date) %>%
  group_by(sku_id) %>% summarise(inv0=sum(on_hand_qty), .groups="drop")
inv0_by_sku <- tibble(sku_id=sku_list) %>% left_join(inv0_by_sku, by="sku_id") %>% mutate(inv0=replace_na(inv0,0))

W <- length(weeks); S <- length(sku_list); L <- length(line_list)
n_x <- W*S*L; n_I <- W*S; n_B <- W*S; n_var <- n_x + n_I + n_B
offset_I <- n_x; offset_B <- n_x + n_I

mh_map <- unit_mh %>% deframe()
hold_map <- costs %>% select(sku_id, hold_cost_week) %>% deframe()
stock_map <- costs %>% select(sku_id, stockout_cost) %>% deframe()
penalty_mat <- grid %>% mutate(key=paste0(week,"|",sku_id)) %>% select(key, avg_penalty) %>% deframe()
demand_map  <- grid %>% mutate(key=paste0(week,"|",sku_id)) %>% select(key, demand_qty) %>% deframe()

obj <- rep(0, n_var)
for (w in seq_len(W)){
  for (s in seq_len(S)){
    sku <- sku_list[s]
    obj[offset_I + (w-1)*S + s] <- hold_map[[sku]]
    obj[offset_B + (w-1)*S + s] <- stock_map[[sku]] + penalty_mat[[paste0(weeks[w],"|",sku)]]
  }
}

con_mat <- list(); con_dir <- c(); con_rhs <- c()

# capacity
for (w in seq_len(W)){
  for (l in seq_len(L)){
    row <- rep(0, n_var)
    for (s in seq_len(S)){
      pos <- (w-1)*S*L + (s-1)*L + l
      row[pos] <- mh_map[[sku_list[s]]]
    }
    con_mat[[length(con_mat)+1]] <- row; con_dir <- c(con_dir, "<="); con_rhs <- c(con_rhs, cap_map[[line_list[l]]])
  }
}

# ineligible x -> 0
for (w in seq_len(W)){
  for (s in seq_len(S)){
    for (l in seq_len(L)){
      sku <- sku_list[s]; line <- line_list[l]
      if (!(paste0(sku,"|",line) %in% elig_set)){
        pos <- (w-1)*S*L + (s-1)*L + l
        row <- rep(0, n_var); row[pos] <- 1
        con_mat[[length(con_mat)+1]] <- row; con_dir <- c(con_dir, "<="); con_rhs <- c(con_rhs, 0)
      }
    }
  }
}

# balance
for (w in seq_len(W)){
  for (s in seq_len(S)){
    row <- rep(0, n_var)
    Ipos <- offset_I + (w-1)*S + s
    Bpos <- offset_B + (w-1)*S + s
    row[Ipos] <- 1; row[Bpos] <- -1

    rhs0 <- 0
    if (w > 1){
      Iprev <- offset_I + (w-2)*S + s
      Bprev <- offset_B + (w-2)*S + s
      row[Iprev] <- -1; row[Bprev] <- 1
    } else {
      rhs0 <- inv0_by_sku$inv0[inv0_by_sku$sku_id==sku_list[s]]
    }

    for (l in seq_len(L)){
      x_pos <- (w-1)*S*L + (s-1)*L + l
      row[x_pos] <- row[x_pos] - 1
    }

    dem_qty <- demand_map[[paste0(weeks[w],"|",sku_list[s])]]
    rhs <- if (w==1) (rhs0 - dem_qty) else (0 - dem_qty)

    con_mat[[length(con_mat)+1]] <- row; con_dir <- c(con_dir, "="); con_rhs <- c(con_rhs, rhs)
  }
}
con <- do.call(rbind, con_mat)

sol <- lp(direction="min", objective.in=obj, const.mat=con, const.dir=con_dir, const.rhs=con_rhs, all.int=FALSE)
stopifnot(sol$status==0)

x_sol <- sol$solution[1:n_x]
plan <- expand_grid(w=seq_len(W), s=seq_len(S), l=seq_len(L)) %>%
  mutate(pos=(w-1)*S*L + (s-1)*L + l,
         week=weeks[w],
         sku_id=sku_list[s],
         production_line_id=line_list[l],
         planned_qty=x_sol[pos]) %>%
  filter(planned_qty > 1e-6) %>%
  mutate(planned_qty=round(planned_qty,0))

lp_cost <- tibble(
  total_objective = sol$objval,
  holding_cost = sum(obj[(n_x+1):(n_x+n_I)] * sol$solution[(n_x+1):(n_x+n_I)]),
  shortage_cost = sum(obj[(n_x+n_I+1):n_var] * sol$solution[(n_x+n_I+1):n_var])
)

write_csv(plan, file.path(base_dir, "optimization_outputs_r", "production_plan_weekly_lp.csv"))
write_csv(lp_cost, file.path(base_dir, "optimization_outputs_r", "lp_cost_breakdown.csv"))
```

### Production plan insight: Which lines got leveled?

```{r lp-plot}
# Interpreting the LP: capacity is in MACHINE-HOURS, so we also plot machine-hour load (not only units)
plan_enriched <- plan %>%
  left_join(unit_mh, by="sku_id") %>%
  mutate(req_mh = planned_qty * mh_per_unit)

plan_line <- plan_enriched %>%
  group_by(week, production_line_id) %>%
  summarise(
    planned_units = sum(planned_qty),
    required_mh   = sum(req_mh),
    .groups="drop"
  ) %>%
  mutate(
    week_dt = ymd(week),
    week_ts = datetime_to_timestamp(as.POSIXct(week_dt))
  )

cap_df <- lines_cap %>% select(production_line_id, weekly_capacity_machine_hours)

plan_line <- plan_line %>%
  left_join(cap_df, by="production_line_id") %>%
  mutate(util = if_else(weekly_capacity_machine_hours > 0, required_mh / weekly_capacity_machine_hours, NA_real_))

# Quick sanity table (top bottleneck weeks)
plan_line %>%
  arrange(desc(util)) %>%
  select(week, production_line_id, planned_units, required_mh, weekly_capacity_machine_hours, util) %>%
  head(10) %>%
  knitr::kable(digits = 2)

highchart() %>%
  hc_chart(zoomType="x") %>%
  hc_title(text="Production LP — machine-hour utilization by line") %>%
  hc_subtitle(text="Y = required machine-hours / weekly capacity (closer to 1 means tight; >1 would be infeasible)") %>%
  hc_xAxis(type="datetime") %>%
  hc_yAxis(title=list(text="Utilization"), min=0) %>%
  hc_add_series_list(
    plan_line %>% group_by(production_line_id) %>%
      group_map(~ list(
        name = unique(.x$production_line_id),
        type = "line",
        data = .x %>% transmute(x=week_ts, y=util) %>% list_parse2()
      ))
  ) %>%
  hc_tooltip(shared=TRUE, crosshairs=TRUE) %>%
  hc_exporting(enabled = TRUE) %>%
  hc_lang_safe(hc_lang)

highchart() %>%
  hc_chart(zoomType="x") %>%
  hc_title(text="Production LP — weekly planned units by line (secondary view)") %>%
  hc_xAxis(type="datetime") %>%
  hc_yAxis(title=list(text="Planned units")) %>%
  hc_add_series_list(
    plan_line %>% group_by(production_line_id) %>%
      group_map(~ list(
        name = unique(.x$production_line_id),
        type = "line",
        data = .x %>% transmute(x=week_ts, y=planned_units) %>% list_parse2()
      ))
  ) %>%
  hc_tooltip(shared=TRUE, crosshairs=TRUE) %>%
  hc_exporting(enabled = TRUE) %>%
  hc_lang_safe(hc_lang)

```

## 5.3 Optimization 2 — Network Flow (WH → DC) with unmet slack

If supply or lane capacity is insufficient, we allow **unmet demand** (with a big penalty) so the model stays feasible and the shortage is visible.

```{r network-flow}
lanes <- B$lanes %>%
  filter(from_node %in% c("WH_NORTH","WH_SOUTH"),
         str_detect(to_node, "^DC_")) %>%
  mutate(weekly_capacity = capacity_units_per_day * 6)

city_to_dc <- c("Hanoi"="DC_HN","Hai Phong"="DC_HN","Da Nang"="DC_DN","Nha Trang"="DC_DN","HCMC"="DC_HCMC","Can Tho"="DC_CT")
dem2 <- B$dem %>%
  left_join(B$customers %>% select(customer_id, city), by="customer_id") %>%
  mutate(dc_id = city_to_dc[city],
         week = format(floor_date(due_date, unit="week", week_start=1), "%Y-%m-%d"))

weeks2 <- sort(unique(dem2$week))
dcs <- sort(unique(dem2$dc_id))
origins <- sort(unique(lanes$from_node))

dem_dc <- dem2 %>% group_by(week, dc_id) %>% summarise(demand_units=sum(demand_qty), .groups="drop")

# supply from LP (factory -> WH)
lines2 <- B$lines %>% select(production_line_id, factory_id)
plan_wh <- plan %>%
  left_join(lines2, by="production_line_id") %>%
  mutate(wh = if_else(factory_id=="F1","WH_NORTH","WH_SOUTH")) %>%
  group_by(week, wh) %>%
  summarise(supply_units = sum(planned_qty), .groups="drop") %>%
  mutate(week = as.character(week))

supply_grid <- expand_grid(week=weeks2, wh=origins) %>%
  left_join(plan_wh, by=c("week","wh")) %>%
  mutate(supply_units = replace_na(supply_units, 0))

dem_grid <- expand_grid(week=weeks2, dc_id=dcs) %>%
  left_join(dem_dc, by=c("week","dc_id")) %>%
  mutate(demand_units = replace_na(demand_units, 0))

out_rows <- list()
cost_rows <- list()
BIG_M <- 1e4

for (wk in weeks2){
  supply_wk <- supply_grid %>% filter(week==wk)
  demand_wk <- dem_grid %>% filter(week==wk)

  pairs <- expand_grid(from_node=origins, to_node=dcs) %>%
    mutate(key=paste0(from_node,"|",to_node)) %>%
    left_join(lanes %>% mutate(key=paste0(from_node,"|",to_node)) %>%
                select(key, transport_cost_per_unit, weekly_capacity), by="key")

  n_x <- nrow(pairs)
  n_u <- length(dcs)
  n <- n_x + n_u

  obj <- c((pairs$transport_cost_per_unit %>% replace_na(1e6)), rep(BIG_M, n_u))
  cap_vec <- pairs$weekly_capacity; cap_vec[is.na(cap_vec)] <- 0

  con <- list(); dir <- c(); rhs <- c()

  for (o in origins){
    row <- rep(0,n); row[which(pairs$from_node==o)] <- 1
    con[[length(con)+1]] <- row; dir <- c(dir, "<=")
    rhs <- c(rhs, supply_wk$supply_units[supply_wk$wh==o])
  }

  for (i in seq_along(dcs)){
    dc <- dcs[i]
    row <- rep(0,n)
    row[which(pairs$to_node==dc)] <- 1
    row[n_x+i] <- 1
    con[[length(con)+1]] <- row; dir <- c(dir, ">=")
    rhs <- c(rhs, demand_wk$demand_units[demand_wk$dc_id==dc])
  }

  for (i in seq_len(n_x)){
    row <- rep(0,n); row[i] <- 1
    con[[length(con)+1]] <- row; dir <- c(dir, "<=")
    rhs <- c(rhs, cap_vec[i])
  }

  con_mat <- do.call(rbind, con)
  sol2 <- lp(direction="min", objective.in=obj, const.mat=con_mat, const.dir=dir, const.rhs=rhs, all.int=FALSE)
  stopifnot(sol2$status==0)

  x <- sol2$solution[1:n_x]
  u <- sol2$solution[(n_x+1):n]

  out_rows[[length(out_rows)+1]] <- pairs %>%
    mutate(week=wk, ship_units=x) %>%
    filter(ship_units > 1e-6) %>%
    mutate(ship_units=round(ship_units,0))

  cost_rows[[length(cost_rows)+1]] <- tibble(
    week = wk,
    transport_cost = sum((pairs$transport_cost_per_unit %>% replace_na(1e6)) * x),
    unmet_units = sum(u)
  )
}

flow_cost <- bind_rows(cost_rows) %>% mutate(week_dt = ymd(week))
write_csv(flow_cost, file.path(base_dir, "optimization_outputs_r", "network_flow_cost_summary_weekly.csv"))
```

```{r flow-plot}
flow_cost <- flow_cost %>%
  mutate(week_ts = datetime_to_timestamp(as.POSIXct(week_dt))) %>%
  arrange(week_dt)

highchart() %>%
  hc_chart(zoomType="x") %>%
  hc_title(text="Network Flow — transport cost (weekly)") %>%
  hc_xAxis(type="datetime") %>%
  hc_yAxis(title=list(text="Cost")) %>%
  hc_add_series(flow_cost, "line",
                hcaes(x=week_ts, y=transport_cost),
                color=COL_BEFORE, name="Cost") %>%
  hc_tooltip(shared=TRUE, crosshairs=TRUE) %>%
  hc_exporting(enabled = TRUE) %>%
  hc_lang_safe(hc_lang)

highchart() %>%
  hc_chart(zoomType="x") %>%
  hc_title(text="Network Flow — unmet demand units (weekly)") %>%
  hc_xAxis(type="datetime") %>%
  hc_yAxis(title=list(text="Units")) %>%
  hc_add_series(flow_cost, "column",
                hcaes(x=week_ts, y=unmet_units),
                color=COL_BAD, name="Unmet", opacity=0.6) %>%
  hc_tooltip(shared=TRUE, crosshairs=TRUE) %>%
  hc_exporting(enabled = TRUE) %>%
  hc_lang_safe(hc_lang)

```

# 6) Only now: Compare BEFORE vs AFTER (impact)

We use the same measurement logic on both scenarios, but we compare *after we know what we are fixing*.

```{r compare-metrics}
compute_weekly <- function(x){
  prod <- x$prod %>% mutate(
    cycle_min = as.numeric(difftime(step_end_time, step_start_time, units="mins")),
    week = as.Date(floor_date(step_start_time, "week", week_start=1))
  ) %>% arrange(work_order_id, step_start_time) %>%
    group_by(work_order_id) %>%
    mutate(prev_end = lag(step_end_time),
           wait_min = pmax(0, as.numeric(difftime(step_start_time, prev_end, units="mins")))) %>%
    ungroup()

  prod %>% group_by(week) %>%
    summarise(
      produced_qty=sum(produced_qty),
      rejected_qty=sum(rejected_qty),
      rework_qty=sum(rework_qty),
      avg_wait=mean(wait_min, na.rm=TRUE),
      avg_cycle=mean(cycle_min, na.rm=TRUE),
      p95_cycle=quantile(cycle_min, 0.95, na.rm=TRUE),
      .groups="drop"
    ) %>% mutate(scenario=x$scenario)
}

cmp <- bind_rows(compute_weekly(B), compute_weekly(A)) %>%
  mutate(week_ts = datetime_to_timestamp(as.POSIXct(week))) %>%
  arrange(week)

# Interactive compare charts (use week_ts for datetime axis)
highchart() %>%
  hc_chart(zoomType="x") %>%
  hc_title(text="Impact — Throughput (Before vs After)") %>%
  hc_xAxis(type="datetime") %>%
  hc_yAxis(title=list(text="Units")) %>%
  hc_add_series(cmp %>% filter(scenario=="before"), "line",
                hcaes(x=week_ts, y=produced_qty),
                name="before", color=COL_BEFORE) %>%
  hc_add_series(cmp %>% filter(scenario=="after"),  "line",
                hcaes(x=week_ts, y=produced_qty),
                name="after",  color=COL_AFTER) %>%
  hc_tooltip(shared=TRUE, crosshairs=TRUE) %>%
  hc_exporting(enabled = TRUE) %>%
  hc_lang_safe(hc_lang)

highchart() %>%
  hc_chart(zoomType="x") %>%
  hc_title(text="Impact — Waiting time (Before vs After)") %>%
  hc_xAxis(type="datetime") %>%
  hc_yAxis(title=list(text="Minutes")) %>%
  hc_add_series(cmp %>% filter(scenario=="before"), "line",
                hcaes(x=week_ts, y=avg_wait),
                name="before", color=COL_BEFORE) %>%
  hc_add_series(cmp %>% filter(scenario=="after"),  "line",
                hcaes(x=week_ts, y=avg_wait),
                name="after",  color=COL_AFTER) %>%
  hc_tooltip(shared=TRUE, crosshairs=TRUE) %>%
  hc_exporting(enabled = TRUE) %>%
  hc_lang_safe(hc_lang)

```

# 7) Closing: the storyline in one paragraph

- Baseline evidence points to **queueing/waiting concentrated in specific steps**, confirmed by **high utilization lines** and **quality Pareto**.
- Lean countermeasures reduce variability and rework at the source; optimization turns that into **capacity-feasible weekly plans** and **cost-aware shipments**.
- Only after diagnosing the root cause do we compare results — and the improvement becomes credible, not “dashboard theatre”.
